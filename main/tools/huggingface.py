import os
import time
import tqdm
import requests

try:
    import wget
except:
    wget = None

def HF_download_file(url, output_path=None, max_retries=3, retry_delay=5):
    """
    T·∫£i file t·ª´ HuggingFace v·ªõi retry mechanism
    """
    url = url.replace("/blob/", "/resolve/").replace("?download=true", "").strip()
    output_path = os.path.basename(url) if output_path is None else (os.path.join(output_path, os.path.basename(url)) if os.path.isdir(output_path) else output_path)

    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)

    # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i ch∆∞a (logic c≈© b·ªã b·ªè ƒë·ªÉ allow resume)
    # Block c≈©: return ngay n·∫øu file > 0. Gi·ªù s·∫Ω ƒë·ªÉ xu·ªëng d∆∞·ªõi check header Range
    pass

    # Th·ª≠ t·∫£i b·∫±ng requests (c√≥ retry v√† progress bar t·ªët h∆°n)
    for attempt in range(max_retries):
        try:
            # Ki·ªÉm tra file ƒë√£ t·∫£i m·ªôt ph·∫ßn ƒë·ªÉ resume
            resume_header = {}
            existing_size = 0
            if os.path.exists(output_path):
                existing_size = os.path.getsize(output_path)
                if existing_size > 0:
                    resume_header = {'Range': f'bytes={existing_size}-'}
                    print(f"Resume t·∫£i file t·ª´ byte {existing_size}")

            # TƒÉng timeout v√† gi·∫£m chunk size ƒë·ªÉ ·ªïn ƒë·ªãnh h∆°n
            response = requests.get(url, stream=True, timeout=600, headers=resume_header)
            
            # Handle 416 Range Not Satisfiable (nghƒ©a l√† file ƒë√£ t·∫£i xong r·ªìi)
            if response.status_code == 416:
                print(f"File ƒë√£ t·∫£i ƒë·∫ßy ƒë·ªß (Server tr·∫£ v·ªÅ 416): {output_path}")
                return output_path

            if response.status_code == 200 or response.status_code == 206:  # 206 = Partial Content
                total_size = int(response.headers.get("content-length", 0))
                if existing_size > 0 and response.status_code == 206:
                    total_size = existing_size + total_size
                
                mode = "ab" if existing_size > 0 else "wb"
                progress_bar = tqdm.tqdm(
                    total=total_size, 
                    initial=existing_size,
                    desc=os.path.basename(url), 
                    ncols=100, 
                    unit="B", 
                    unit_scale=True,
                    unit_divisor=1024,
                    leave=True
                )

                # Gi·∫£m chunk size xu·ªëng 1MB ƒë·ªÉ ·ªïn ƒë·ªãnh h∆°n v·ªõi m·∫°ng kh√¥ng ·ªïn ƒë·ªãnh
                chunk_size = 1024 * 1024  # 1MB chunks
                with open(output_path, mode) as f:
                    try:
                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                progress_bar.update(len(chunk))
                                f.write(chunk)
                                f.flush()  # Force write to disk ngay l·∫≠p t·ª©c
                    except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError) as e:
                        # N·∫øu b·ªã l·ªói, l∆∞u ph·∫ßn ƒë√£ t·∫£i ƒë·ªÉ c√≥ th·ªÉ resume
                        f.flush()
                        raise e

                progress_bar.close()
                
                # Ki·ªÉm tra file ƒë√£ t·∫£i ƒë·∫ßy ƒë·ªß
                final_size = os.path.getsize(output_path)
                if total_size == 0:
                    # N·∫øu kh√¥ng bi·∫øt t·ªïng size, coi nh∆∞ th√†nh c√¥ng
                    print(f"‚úì T·∫£i ho√†n t·∫•t: {output_path} ({final_size / (1024*1024):.2f} MB)")
                    return output_path
                elif final_size == total_size:
                    print(f"‚úì T·∫£i th√†nh c√¥ng: {output_path} ({final_size / (1024*1024):.2f} MB)")
                    return output_path
                elif total_size > 0 and final_size >= total_size * 0.99:  # Cho ph√©p sai s·ªë 1%
                    print(f"‚úì T·∫£i g·∫ßn nh∆∞ ho√†n t·∫•t: {output_path} ({final_size / (1024*1024):.2f} MB / {total_size / (1024*1024):.2f} MB)")
                    return output_path
                else:
                    # File ch∆∞a ƒë·∫ßy ƒë·ªß, raise exception ƒë·ªÉ retry
                    raise Exception(f"File t·∫£i kh√¥ng ƒë·∫ßy ƒë·ªß. K·ª≥ v·ªçng: {total_size} bytes ({total_size / (1024*1024):.2f} MB), Th·ª±c t·∫ø: {final_size} bytes ({final_size / (1024*1024):.2f} MB)")
                    
            else:
                raise ValueError(f"HTTP {response.status_code}: {response.text[:100]}")
                
        except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            current_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0
            print(f"L·∫ßn th·ª≠ {attempt + 1}/{max_retries} th·∫•t b·∫°i: {str(e)}")
            print(f"ƒê√£ t·∫£i ƒë∆∞·ª£c: {current_size / (1024*1024):.2f} MB")
            
            if attempt < max_retries - 1:
                # TƒÉng th·ªùi gian ƒë·ª£i sau m·ªói l·∫ßn th·ª≠
                wait_time = retry_delay * (attempt + 1)
                print(f"ƒê·ª£i {wait_time} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                time.sleep(wait_time)
            else:
                current_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0
                if current_size > 1024 * 1024:  # N·∫øu ƒë√£ t·∫£i ƒë∆∞·ª£c > 1MB
                    print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: File t·∫£i kh√¥ng ƒë·∫ßy ƒë·ªß ({current_size / (1024*1024):.2f} MB)")
                    print(f"üí° G·ª£i √Ω:")
                    print(f"   1. Ch·∫°y l·∫°i ch·ª©c nƒÉng ƒë·ªÉ ti·∫øp t·ª•c t·∫£i (resume)")
                    print(f"   2. Ho·∫∑c t·∫£i th·ªß c√¥ng t·ª´: {url}")
                    print(f"   3. ƒê·∫∑t file v√†o: {os.path.dirname(output_path)}")
                
        except Exception as e:
            print(f"L·∫ßn th·ª≠ {attempt + 1}/{max_retries} th·∫•t b·∫°i: {str(e)}")
            if attempt < max_retries - 1:
                wait_time = retry_delay * (attempt + 1)
                print(f"ƒê·ª£i {wait_time} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                time.sleep(wait_time)
            else:
                # N·∫øu v·∫´n l·ªói, th·ª≠ d√πng wget (fallback)
                if wget is not None:
                    try:
                        print("Th·ª≠ t·∫£i b·∫±ng wget...")
                        wget.download(url, out=output_path)
                        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                            return output_path
                    except Exception as wget_error:
                        print(f"Wget c≈©ng th·∫•t b·∫°i: {wget_error}")
                
                raise Exception(f"Kh√¥ng th·ªÉ t·∫£i file sau {max_retries} l·∫ßn th·ª≠. L·ªói cu·ªëi: {str(e)}")

    return output_path